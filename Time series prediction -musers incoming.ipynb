{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/38714959/understanding-keras-lstms?rq=1\n",
    "https://github.com/rishikksh20/LSTM-Time-Series-Analysis/blob/master/LSTM_Time_Series_Analysis.ipynb\n",
    "https://github.com/sudharsan13296/Bitcoin-price-Prediction-using-LSTM/blob/master/Bitcoin%20price%20prediction%20(Time%20series)%20using%20LSTM%20RNN.ipynb\n",
    "https://stackoverflow.com/questions/38714959/understanding-keras-lstms?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from numpy import concatenate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from keras import regularizers\n",
    "import math\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, threshold=5):\n",
    "    mean= data.mean()\n",
    "    std= data.std()\n",
    "    idx= np.abs((data-mean)/std) <= threshold\n",
    "    return data[idx].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********Load data**************************\n",
    "\n",
    "dataset = pd.read_csv('murdoch_user_incoming_traffic.csv', usecols=[2])\n",
    "dataset.dropna(0,inplace= True)\n",
    "dataset= np.array(dataset)\n",
    "print('dataset with outlier', dataset.shape)\n",
    "dataset= dataset.astype('float32')\n",
    "dataset= remove_outliers(dataset)\n",
    "print('dataset after removing outlier', dataset.shape)\n",
    "\n",
    "# *****************split into train and test sets********************\n",
    "\n",
    "train_size = int(len(dataset) * 0.80)\n",
    "test_size = len(dataset) - train_size\n",
    "data_train = dataset[0:train_size]\n",
    "data_test = dataset[train_size:len(dataset)]\n",
    "print('Data_train', data_train.shape, 'Data_test',data_test.shape)\n",
    "\n",
    "# ********Normalize the data******************\n",
    "\n",
    "scaler= MinMaxScaler (feature_range= (-1,1))\n",
    "train_scaled = scaler.fit_transform(data_train)\n",
    "test_scaled = scaler.transform(data_test)\n",
    "print('Train_scaled',train_scaled.shape,' Test scaled', test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************frame a sequence as a supervised learning problem*************\n",
    "\n",
    "def prepare_seq2seq_data(dataset, look_back=1):\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "look_back = 40\n",
    "train_X, train_y = prepare_seq2seq_data(train_scaled , look_back)\n",
    "test_X, test_y = prepare_seq2seq_data(test_scaled , look_back)\n",
    "\n",
    "print('train_X',train_X.shape, 'train_y',train_y.shape)\n",
    "print('test_X', test_X.shape, 'test_y',test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******Reshape from[samples, timesteps] into [samples, timesteps, features]*************\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0],1, train_X.shape[1])\n",
    "test_X = test_X.reshape(test_X.shape[0],1, test_X.shape[1])\n",
    "print('train_X',train_X.shape, 'train_y',train_y.shape)\n",
    "print('test_X', test_X.shape, 'test_y',test_y.shape)\n",
    "\n",
    "# convert 1 D to 2D array\n",
    "#test_y = test_y.reshape((test_y.shape[0], 1))\n",
    "#print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********RPE******************************\n",
    "def rpe(y_true, y_pred):\n",
    "    \n",
    "    return backend.abs((y_pred - y_true)/y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************Model****************************\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1,look_back),kernel_initializer='glorot_uniform', return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(LSTM(64,kernel_initializer='glorot_uniform',return_sequences=True ))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(32,kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer= 'adam',\n",
    "            loss='mean_squared_error', metrics= [rpe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=100, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [callback_early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y, batch_size = 256,validation_split=0.2, epochs = 5000, verbose=1,\n",
    "                    callbacks=callbacks, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************Model Performance Error  metrics*************************************\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1 D to 2D array\n",
    "train_y = train_y.reshape((train_y.shape[0], 1))\n",
    "#print(test_y.shape)\n",
    "\n",
    "# convert 1 D to 2D array\n",
    "test_y = test_y.reshape((test_y.shape[0], 1))\n",
    "#print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************make predictions*************************************************************\n",
    "\n",
    "trainPredict = model.predict(train_X)\n",
    "testPredict = model.predict(test_X)\n",
    "\n",
    "# *************************invert predictions**************************\n",
    "\n",
    "trainPredict_inv = scaler.inverse_transform(trainPredict)\n",
    "train_y_inv = scaler.inverse_transform(train_y)\n",
    "\n",
    "testPredict_inv = scaler.inverse_transform(testPredict)\n",
    "test_y_inv = scaler.inverse_transform(test_y)\n",
    "\n",
    "\n",
    "# ********************RMSE*************************\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(train_y_inv, trainPredict_inv))\n",
    "print('Train Score: %.2f RMSE' % trainScore)\n",
    "testScore = math.sqrt(mean_squared_error(test_y_inv, testPredict_inv))\n",
    "print('Test Score: %.2f RMSE' % testScore)\n",
    "\n",
    "\n",
    "# *****************Relative Percentage Error******************************\n",
    "\"\"\"\n",
    "def mean_relative_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\"\"\"\n",
    "def rpe(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean((y_pred - y_true) / y_true) * 100\n",
    "\n",
    "rpe = rpe(test_y_inv, testPredict_inv)\n",
    "print('RPE: %.3f' % rpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict_inv.max(), test_y_inv.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ***********************shift train predictions for plotting*******************************\n",
    "\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict_inv\n",
    "    \n",
    "# **********************shift test predictions for plotting*************************************\n",
    "\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict_inv\n",
    "    \n",
    "# ********************Create the plot*************************************************************\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(dataset, label= 'Actual values', color='y')\n",
    "plt.plot(trainPredictPlot, label= 'Train set')\n",
    "plt.plot(testPredictPlot, label= 'Test set')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "#***************************************Model validation loss*****************************************\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data loss', 'Validation data loss'], loc='upper right')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #***************************************RPE*****************************************\n",
    "plt.figure()\n",
    "plt.plot(history.history['rpe'])\n",
    "plt.plot(history.history['val_rpe'])\n",
    "plt.title('RPE')\n",
    "plt.ylabel('Relative percentage error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data error', 'Validation data error'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#********************* Actual value, Predicted value and Prediction Error ***************\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Email traffic\")\n",
    "plt.plot(test_y_inv[:,0], label=\"True value\", linewidth=1,linestyle=\"--\",color= 'green')\n",
    "plt.plot(testPredict_inv[:,0], label=\"Predicted value\", linewidth=1,color='blue')\n",
    "\n",
    "error = abs(test_y_inv[:,0] - testPredict_inv[:,0])\n",
    "plt.plot(error, label='Error',color= 'orange', linewidth=1, linestyle=\"--\")\n",
    "plt.legend(bbox_to_anchor=(1, .99))\n",
    "plt.show()\n",
    "\n",
    "#******************************* True value vs Prediction **********************/\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Email traffic\")\n",
    "plt.plot (test_y_inv[:,0], label=\"True value\", linewidth=1,color= 'green', linestyle=\"--\")\n",
    "plt.plot(testPredict_inv[:,0], label=\"Predicted value\", linewidth=1,color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
